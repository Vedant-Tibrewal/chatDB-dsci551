{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vedanttibrewal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/vedanttibrewal/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vedanttibrewal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'the',\n",
    "    'i', 'me', 'my', 'mine', 'myself', 'you', 'your', 'yours', 'yourself', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'we', 'our', 'ours', 'ourselves', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "    'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'do', 'does', 'did', 'have', 'has', 'had', 'can', 'could', 'shall', 'should', 'will', 'would', 'may', 'might', 'must',\n",
    "    'about', 'across', 'after', 'against', 'along', 'around', 'at', 'before', 'behind', 'below', 'beneath', 'beside', 'during', 'into', 'near', 'off', 'out', 'through', 'toward', 'under', 'up', 'with',\n",
    "    'if', 'then', 'because', 'as', 'until', 'while',\n",
    "    'this', 'that', 'these', 'those', 'such', 'what', 'which', 'whose', 'whoever', 'whatever', 'whichever', 'whomever', 'either', 'neither', 'both',\n",
    "    'very', 'really', 'always', 'never', 'too', 'already', 'often', 'sometimes', 'rarely', 'seldom', 'again', 'further', 'then', 'once', 'here', 'there', 'where', 'why', 'how',\n",
    "    # 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'second', 'third', 'fourth', 'fifth', # find a way to implement it in limit\n",
    "    'few', 'little', 'much', 'enough',\n",
    "    'yes', 'no', 'not', 'okay', 'ok', 'right', 'sure', 'well', 'uh', 'um', 'oh', 'eh', 'hmm', 'just', 'ever', 'yet', 'etc', 'perhaps', 'maybe', 'list'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "aggregate_functions = {\n",
    "    'COUNT': ['count', 'number of', 'quantity of', 'total number of', 'tally', 'enumerate', 'how many'],\n",
    "    'SUM': ['sum', 'total', 'aggregate', 'combined', 'add up', 'overall', 'cumulative'],\n",
    "    'AVG': ['average', 'mean', 'typical', 'median', 'expected value', 'norm', 'central tendency'],\n",
    "    'MAX': ['maximum', 'highest', 'most', 'top', 'peak', 'greatest', 'largest', 'biggest', 'uppermost'],\n",
    "    'MIN': ['minimum', 'lowest', 'least', 'bottom', 'smallest', 'tiniest', 'least', 'floor'],\n",
    "    'DISTINCT': ['unique', 'different', 'distinct', 'individual', 'separate', 'non-duplicate', 'exclusive'],\n",
    "    'GROUP_CONCAT': ['concatenate', 'combine strings', 'join', 'merge text', 'string aggregation', 'text combination'],\n",
    "    'FIRST': ['first', 'initial', 'earliest', 'primary', 'leading', 'opening', 'foremost'], # limit implementation along with number\n",
    "    'LAST': ['last', 'final', 'latest', 'ultimate', 'concluding', 'terminal', 'closing']\n",
    "}\n",
    "\n",
    "comparison_operators = {\n",
    "    '>': ['greater than', 'more than', 'above', 'over', 'exceeding', 'surpassing', 'beyond', 'higher than', 'in excess of'],\n",
    "    '<': ['less than', 'fewer than', 'below', 'under', 'beneath', 'lower than', 'not as much as', 'smaller than'],\n",
    "    '=': ['equal to', 'same as', 'identical to', 'matching', 'equivalent to', 'corresponds to', 'is', 'for'],\n",
    "    '!=': ['not equal to', 'different from', 'excluding', 'not the same as', 'dissimilar to', 'unlike', 'other than'],\n",
    "    '>=': ['greater than or equal to', 'at least', 'no less than', 'minimum of', 'not below', ' starting from'],\n",
    "    '<=': ['less than or equal to', 'at most', 'no more than', 'maximum of', 'not above', 'up to'],\n",
    "    'BETWEEN': ['between', 'in the range of', 'within the bounds of', 'inside the limits of'],\n",
    "    'IN': ['in', 'within', 'among', 'included in', 'part of', 'contained in', 'one of'],\n",
    "    'NOT IN': ['not in', 'outside of', 'excluded from', 'not among', 'not part of', 'not contained in'],\n",
    "    'LIKE': ['like', 'similar to', 'resembling', 'matching pattern', 'corresponding to'],\n",
    "    'NOT LIKE': ['not like', 'dissimilar to', 'unlike', 'not matching pattern', 'different from pattern']\n",
    "}\n",
    "\n",
    "logical_operators = {\n",
    "    'AND': ['and', 'also', 'as well as', 'in addition to', 'plus', 'together with', 'along with', 'including'],\n",
    "    'OR': ['or', 'alternatively', 'either', 'otherwise', 'else', 'and/or'],\n",
    "    'NOT': ['not', 'except', 'excluding', 'other than', 'but not', 'save for', 'apart from']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = {\n",
    "    'INTEGER': ['integer', 'int', 'whole number', 'numeric'],\n",
    "    'FLOAT': ['float', 'decimal', 'real number', 'fractional number'],\n",
    "    'VARCHAR': ['string', 'text', 'characters', 'alphanumeric'],\n",
    "    'DATE': ['date', 'calendar day', 'day'],\n",
    "    'TIMESTAMP': ['timestamp', 'date and time', 'moment', 'point in time'],\n",
    "    'BOOLEAN': ['boolean', 'true/false', 'yes/no', 'binary']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order matters\n",
    "sql_clauses = {\n",
    "    'FROM': ['from', 'in', 'out of', 'sourced from', 'derived from', 'based on'],\n",
    "    'WHERE': ['where', 'for which', 'that have', 'meeting the condition', 'satisfying', 'fulfilling'],\n",
    "    'GROUP BY': ['group by', 'categorize by', 'classify by', 'organize by', 'arrange by', 'cluster by', 'for each', 'broken down by', 'per', 'by'], # check about 'by'\n",
    "    'HAVING': ['having', 'with the condition', 'subject to', 'meeting the criteria'],\n",
    "    'ORDER BY': ['order by', 'sort by', 'arrange by', 'rank by', 'sequence by'],\n",
    "    'LIMIT': ['limit', 'top', 'first', 'restrict to', 'cap at', 'only show'],\n",
    "    'JOIN': ['join', 'combine', 'merge', 'connect', 'link', 'associate'],\n",
    "    'UNION': ['union', 'combine', 'merge', 'incorporate', 'consolidate', 'unite'],\n",
    "    'INTERSECT': ['intersect', 'in common', 'shared by', 'mutual', 'overlapping'],\n",
    "    'EXCEPT': ['except', 'subtract', 'exclude', 'remove', 'omit', 'leave out'],\n",
    "    'SELECT': ['show', 'list', 'give', 'return', 'fetch', 'retrieve', 'get', 'find', 'which', 'what is the', 'what is', 'what are', 'what'], # 'display\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_string(text, replace_dict):\n",
    "#     # Create a reverse mapping from values to keys\n",
    "#     value_to_key = {}\n",
    "#     for key, values in replace_dict.items():\n",
    "#         for value in values:\n",
    "#             value_to_key[value.lower()] = key.lower()\n",
    "    \n",
    "#     # Split the text into words\n",
    "#     words = text.split()\n",
    "    \n",
    "#     # Replace words\n",
    "#     replaced_words = [value_to_key.get(word.lower(), word) for word in words]\n",
    "    \n",
    "#     return ' '.join(replaced_words)\n",
    "\n",
    "def replace_string(text, replace_dict):\n",
    "    # Create a reverse mapping from values to keys\n",
    "    value_to_key = {}\n",
    "    for key, values in replace_dict.items():\n",
    "        for value in values:\n",
    "            value_to_key[value.lower()] = key.lower()\n",
    "    \n",
    "    # Create a regex pattern for matching words\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(word) for word in value_to_key.keys()) + r')\\b'\n",
    "    \n",
    "    # Function to replace matched words\n",
    "    def replace_word(match):\n",
    "        return value_to_key.get(match.group(0).lower(), match.group(0))\n",
    "    \n",
    "    # Perform the replacement\n",
    "    replaced_text = re.sub(pattern, replace_word, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return replaced_text\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    # pattern = r'[^\\w\\s()*\\d-]|(?<!\\d)-(?!\\d)'\n",
    "    # text = re.sub(pattern, '', text)\n",
    "    text = re.sub(r'\\?', '', text)\n",
    "    text = re.sub(r',', '', text)\n",
    "    pattern = r'\\b(\\d+)-(\\d+)\\b'\n",
    "    text = re.sub(pattern, r'\\1 to \\2', text)\n",
    "\n",
    "    # substitute words\n",
    "    text = replace_string(text, sql_clauses)\n",
    "    text = replace_string(text, aggregate_functions)\n",
    "    # from \\d+ -> >=\n",
    "    text = replace_string(text, comparison_operators)\n",
    "    between_pattern = r'from \\b(\\w+|\\d+)\\b to \\b(\\w+|\\d+)\\b | \\b(\\w+|\\d+)\\b to \\b(\\w+|\\d+)\\b'\n",
    "    text = re.sub(between_pattern, r\" between(\\1, \\2)\", text)\n",
    "    text = replace_string(text, logical_operators)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    #  load custom stop words\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['42', '3.14', '2.71828e-1', '\"Hello, World!\"']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_matches(text):\n",
    "    # Regex pattern to match numbers, decimals, exponents, and quoted strings\n",
    "    pattern = r\"\"\"\n",
    "        (?<!\\w)            # Negative lookbehind to ensure no word character before\n",
    "        (                  # Start of group\n",
    "            \\d+\\.\\d+       # Decimal numbers\n",
    "            (?:[eE][+-]?\\d+)?  # Optional exponent part\n",
    "            |              # OR\n",
    "            \\d+[eE][+-]?\\d+  # Numbers with exponents\n",
    "            |              # OR\n",
    "            \\d+            # Whole numbers\n",
    "            |              # OR\n",
    "            \"(?:\\\\.|[^\"\\\\])*\"  # Double-quoted strings, allowing for escaped quotes\n",
    "            |              # OR\n",
    "            '(?:\\\\.|[^'\\\\])*'  # Single-quoted strings, allowing for escaped quotes\n",
    "        )                  # End of group\n",
    "        (?!\\w)             # Negative lookahead to ensure no word character after\n",
    "    \"\"\"\n",
    "    \n",
    "    matches = re.findall(pattern, text, flags=re.VERBOSE)\n",
    "    return matches\n",
    "\n",
    "# Example usage\n",
    "text = 'Here are some values: 42, 3.14, 2.71828e-1, \"Hello, World!\", and \\'It\\'s a test\\'.'\n",
    "result = find_matches(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top top\n",
      "first first\n",
      "join join\n"
     ]
    }
   ],
   "source": [
    "for sql in sql_clauses.values():\n",
    "    # print(sql)\n",
    "    for clause in sql:\n",
    "        for func in aggregate_functions.values():\n",
    "            for fn in func:\n",
    "                if clause==fn:\n",
    "                    print(clause, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT col1, col2 FROM table1 JOIN table2 ON table1.key = table2.key WHERE cond1 = 'value' GROUP BY col1 HAVING COUNT(*) > 5 ORDER BY col2 DESC LIMIT 10\n",
      "Result: {'columns': ['col1', 'col2'], 'table': 'table1', 'join': {'table': 'table2', 'condition': 'table1.key = table2.key'}, 'where': \"cond1 = 'value'\", 'group_by': ['col1'], 'having': 'COUNT(*) > 5', 'order_by': ['col2 DESC'], 'limit': 10}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_sql_query(query):\n",
    "    # Regular expressions to match SQL query components\n",
    "    select_pattern = r'SELECT\\s+(.*?)\\s+FROM'\n",
    "    from_pattern = r'FROM\\s+(\\w+)'\n",
    "    join_pattern = r'JOIN\\s+(\\w+)\\s+ON\\s+([\\w.]+)\\s*=\\s*([\\w.]+)'\n",
    "    where_pattern = r'WHERE\\s+(.*?)(?:\\s+GROUP BY|\\s+ORDER BY|\\s+LIMIT|$)'\n",
    "    group_by_pattern = r'GROUP BY\\s+(.*?)(?:\\s+HAVING|\\s+ORDER BY|\\s+LIMIT|$)'\n",
    "    having_pattern = r'HAVING\\s+(.*?)(?:\\s+ORDER BY|\\s+LIMIT|$)'\n",
    "    order_by_pattern = r'ORDER BY\\s+(.*?)(?:\\s+LIMIT|$)'\n",
    "    limit_pattern = r'LIMIT\\s+(\\d+)'\n",
    "\n",
    "    # Find matches based on the patterns\n",
    "    select_match = re.search(select_pattern, query, re.IGNORECASE)\n",
    "    from_match = re.search(from_pattern, query, re.IGNORECASE)\n",
    "    join_match = re.search(join_pattern, query, re.IGNORECASE)\n",
    "    where_match = re.search(where_pattern, query, re.IGNORECASE)\n",
    "    group_by_match = re.search(group_by_pattern, query, re.IGNORECASE)\n",
    "    having_match = re.search(having_pattern, query, re.IGNORECASE)\n",
    "    order_by_match = re.search(order_by_pattern, query, re.IGNORECASE)\n",
    "    limit_match = re.search(limit_pattern, query, re.IGNORECASE)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    if select_match:\n",
    "        result['columns'] = [col.strip() for col in select_match.group(1).split(',')]\n",
    "\n",
    "    if from_match:\n",
    "        result['table'] = from_match.group(1)\n",
    "\n",
    "    if join_match:\n",
    "        result['join'] = {\n",
    "            'table': join_match.group(1),\n",
    "            'condition': f\"{join_match.group(2)} = {join_match.group(3)}\"\n",
    "        }\n",
    "\n",
    "    if where_match:\n",
    "        result['where'] = where_match.group(1)\n",
    "\n",
    "    if group_by_match:\n",
    "        result['group_by'] = [col.strip() for col in group_by_match.group(1).split(',')]\n",
    "\n",
    "    if having_match:\n",
    "        result['having'] = having_match.group(1)\n",
    "\n",
    "    if order_by_match:\n",
    "        result['order_by'] = [col.strip() for col in order_by_match.group(1).split(',')]\n",
    "\n",
    "    if limit_match:\n",
    "        result['limit'] = int(limit_match.group(1))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Test the function\n",
    "query = \"SELECT col1, col2 FROM table1 JOIN table2 ON table1.key = table2.key WHERE cond1 = 'value' GROUP BY col1 HAVING COUNT(*) > 5 ORDER BY col2 DESC LIMIT 10\"\n",
    "result = parse_sql_query(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: select city_name from city where population  =  ( select max ( population ) from city where state_name  =  \"wyoming\" ) and state_name  =  \"wyoming\";\n",
      "Result: {'columns': ['city_name'], 'table': 'city', 'where': 'population  =  ( select max ( population ) from city where state_name  =  \"wyoming\" ) and state_name  =  \"wyoming\";'}\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select city_name from city where population  =  ( select max ( population ) from city where state_name  =  \"wyoming\" ) and state_name  =  \"wyoming\";\"\"\"\n",
    "result = parse_sql_query(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: select distinct t1.paperid from venue as t2 join paper as t1 on t2.venueid  =  t1.venueid where t2.venuename  =  \"chi\";\n",
      "Result: {'columns': ['distinct t1.paperid'], 'table': 'venue', 'where': 't2.venuename  =  \"chi\";'}\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select distinct t1.paperid from venue as t2 join paper as t1 on t2.venueid  =  t1.venueid where t2.venuename  =  \"chi\";\"\"\"\n",
    "\n",
    "result = parse_sql_query(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3w/z9ryb6gj05n_x375lp0r_81r0000gn/T/ipykernel_15009/1522993002.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(f\"{file_path}train.csv\", index_col=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>query</th>\n",
       "      <th>db_id</th>\n",
       "      <th>from</th>\n",
       "      <th>select</th>\n",
       "      <th>where</th>\n",
       "      <th>groupBy</th>\n",
       "      <th>having</th>\n",
       "      <th>orderBy</th>\n",
       "      <th>limit</th>\n",
       "      <th>...</th>\n",
       "      <th>union</th>\n",
       "      <th>except</th>\n",
       "      <th>distinct</th>\n",
       "      <th>count</th>\n",
       "      <th>max</th>\n",
       "      <th>avg</th>\n",
       "      <th>min</th>\n",
       "      <th>sum</th>\n",
       "      <th>and</th>\n",
       "      <th>or</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me what the notes are for South Australia</td>\n",
       "      <td>select notes from table where current slogan =...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the current series where the new serie...</td>\n",
       "      <td>select current series from table where notes =...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the format for South Australia?</td>\n",
       "      <td>select format from table where state/territory...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name the background colour for the Australian ...</td>\n",
       "      <td>select text/background colour from table where...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how many times is the fuel propulsion is cng?</td>\n",
       "      <td>select count fleet series ( quantity ) from ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0    Tell me what the notes are for South Australia    \n",
       "1  What is the current series where the new serie...   \n",
       "2            What is the format for South Australia?   \n",
       "3  Name the background colour for the Australian ...   \n",
       "4      how many times is the fuel propulsion is cng?   \n",
       "\n",
       "                                               query db_id  from  select  \\\n",
       "0  select notes from table where current slogan =...     0     1       1   \n",
       "1  select current series from table where notes =...     0     1       1   \n",
       "2  select format from table where state/territory...     0     1       1   \n",
       "3  select text/background colour from table where...     0     1       1   \n",
       "4  select count fleet series ( quantity ) from ta...     0     1       1   \n",
       "\n",
       "   where  groupBy  having  orderBy  limit  ...  union  except  distinct  \\\n",
       "0      1        0       0        0      0  ...      0       0         0   \n",
       "1      1        0       0        0      0  ...      0       0         0   \n",
       "2      1        0       0        0      0  ...      0       0         0   \n",
       "3      1        0       0        0      0  ...      0       0         0   \n",
       "4      1        0       0        0      0  ...      0       0         0   \n",
       "\n",
       "   count  max  avg  min  sum  and  or  \n",
       "0      0    0    0    0    0    0   0  \n",
       "1      0    0    0    0    0    0   0  \n",
       "2      0    0    0    0    0    0   1  \n",
       "3      0    0    0    0    0    0   1  \n",
       "4      1    0    0    0    0    0   0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/Users/vedanttibrewal/Documents/USC/lectures/sem_1/DSCI-551/project/chatDB-dsci551/dataset/\"\n",
    "train_data = pd.read_csv(f\"{file_path}train.csv\", index_col=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without stop words\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df['processed'] = train_data['question'].map(preprocess_text)\n",
    "temp_df['question'] = train_data['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table & Column identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "def indentify_table(tokens, schema):\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.lower() == \"from\":\n",
    "            table_name = tokens[i + 1]\n",
    "            if table_name in schema:\n",
    "                print(f\"Table identified: {table_name}\")\n",
    "                return table_name\n",
    "    \n",
    "\n",
    "# implement fuzzy logic\n",
    "def indentify_col_tables(tokens, schema):\n",
    "    res = dict()\n",
    "    for token in tokens:\n",
    "        for table, columns in schema.items():\n",
    "            if token in columns: # replace by fuzzy logic\n",
    "                print(f\"Column identified: {token} in table {table}\")\n",
    "                if res[table]:\n",
    "                    res[table].append(token)\n",
    "                else:\n",
    "                    res[table] = list(token)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: ['products', 'categories', 'customers', 'orders', 'order_items']\n",
      "Edges: [('products', 'categories'), ('products', 'order_items'), ('customers', 'orders'), ('orders', 'order_items')]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def create_graph(db_schema):\n",
    "# Create an undirected graph from the SQL structure\n",
    "    G = nx.Graph()  # This creates an undirected graph\n",
    "\n",
    "# Add nodes and edges based on the SQL dictionary\n",
    "    for table, details in db_schema.items():\n",
    "        G.add_node(table)  # Add table as a node\n",
    "        for fk_table in details['fk']:  # Iterate through foreign keys\n",
    "            G.add_edge(table, fk_table)  # Create an undirected edge between current table and foreign key table\n",
    "\n",
    "    # Get nodes and edges for verification\n",
    "    nodes = list(G.nodes)\n",
    "    edges = list(G.edges)\n",
    "\n",
    "    # Output nodes and edges\n",
    "    print(\"Nodes:\", nodes)\n",
    "    print(\"Edges:\", edges)\n",
    "\n",
    "    return G\n",
    "\n",
    "# # Verify that the graph is undirected\n",
    "# print(\"\\nVerifying that the graph is undirected:\")\n",
    "# for edge in edges:\n",
    "#     reverse_edge = (edge[1], edge[0])\n",
    "#     print(f\"Edge {edge} exists: {G.has_edge(*edge)}\")\n",
    "#     print(f\"Reverse edge {reverse_edge} exists: {G.has_edge(*reverse_edge)}\")\n",
    "#     print()\n",
    "\n",
    "G = create_graph(SQL)\n",
    "\n",
    "# # Additional verification\n",
    "# print(f\"Is the graph directed? {G.is_directed()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_graph(db_schema):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes and edges based on the SQL dictionary\n",
    "    for table, details in db_schema.items():\n",
    "        G.add_node(table)  # Add table as a node\n",
    "        for fk_table in details['fk']:  # Iterate through foreign keys\n",
    "            G.add_edge(table, fk_table)  # Create an edge from current table to foreign key table\n",
    "\n",
    "    # Get nodes and edges for verification\n",
    "    nodes = list(G.nodes)\n",
    "    edges = list(G.edges)\n",
    "\n",
    "    # Output nodes and edges\n",
    "    print(nodes)\n",
    "    print(edges)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['products', 'categories', 'customers', 'orders', 'order_items']\n",
      "[('products', 'categories'), ('orders', 'customers'), ('order_items', 'orders'), ('order_items', 'products')]\n"
     ]
    }
   ],
   "source": [
    "dir_g = create_dir_graph(db_schema=SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Undirected Graph\"\"\"\n",
    "\n",
    "# def required_tables_graph(G, start, end, required_tables):\n",
    "#     def dijkstra(graph, start, end):\n",
    "#         distances = {node: float('infinity') for node in graph}\n",
    "#         distances[start] = 0\n",
    "#         pq = [(0, start)]\n",
    "#         previous = {node: None for node in graph}\n",
    "\n",
    "#         while pq:\n",
    "#             current_distance, current_node = heapq.heappop(pq)\n",
    "\n",
    "#             if current_node == end:\n",
    "#                 path = []\n",
    "#                 while current_node:\n",
    "#                     path.append(current_node)\n",
    "#                     current_node = previous[current_node]\n",
    "#                 return path[::-1], current_distance\n",
    "\n",
    "#             for neighbor in graph[current_node]:\n",
    "#                 distance = current_distance + 1  # All edges have weight of 1\n",
    "#                 if distance < distances[neighbor]:\n",
    "#                     distances[neighbor] = distance\n",
    "#                     previous[neighbor] = current_node\n",
    "#                     heapq.heappush(pq, (distance, neighbor))\n",
    "\n",
    "#         return None, float('infinity')\n",
    "\n",
    "#     required_tables = set(required_tables) - {start, end}\n",
    "#     best_path = None\n",
    "#     best_distance = float('infinity')\n",
    "\n",
    "#     def dfs(current_path, current_distance, remaining_required):\n",
    "#         nonlocal best_path, best_distance\n",
    "\n",
    "#         if not remaining_required:\n",
    "#             path, distance = dijkstra(G, current_path[-1], end)\n",
    "#             if path:\n",
    "#                 total_path = current_path + path[1:]\n",
    "#                 total_distance = current_distance + distance\n",
    "#                 if total_distance < best_distance:\n",
    "#                     best_path = total_path\n",
    "#                     best_distance = total_distance\n",
    "#             return\n",
    "\n",
    "#         for node in remaining_required:\n",
    "#             path, distance = dijkstra(G, current_path[-1], node)\n",
    "#             if path:\n",
    "#                 new_path = current_path + path[1:]\n",
    "#                 new_distance = current_distance + distance\n",
    "#                 new_remaining = remaining_required - {node}\n",
    "#                 dfs(new_path, new_distance, new_remaining)\n",
    "\n",
    "#     dfs([start], 0, required_tables)\n",
    "\n",
    "#     return best_path, best_distance\n",
    "\n",
    "# # # Set start, end, and required nodes\n",
    "# # required_tables = ['categories', 'products', 'orders']\n",
    "# # start = required_tables[1]\n",
    "# # end = required_tables[1]\n",
    "\n",
    "# # # Find the shortest path\n",
    "# # required_tables, distance = required_tables_graph(G, start, end, required_tables)\n",
    "\n",
    "# # print(f\"Shortest path: {' -> '.join(required_tables) if required_tables else 'No path found'}\")\n",
    "# # print(f\"Total distance: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def required_tables_graph(G, start, end, required_tables):\n",
    "    # Dijkstra's algorithm for shortest path in NetworkX graph\n",
    "    def dijkstra(graph, start, end):\n",
    "        distances = {node: float('infinity') for node in graph.nodes}\n",
    "        distances[start] = 0\n",
    "        pq = [(0, start)]\n",
    "        previous = {node: None for node in graph.nodes}\n",
    "\n",
    "        while pq:\n",
    "            current_distance, current_node = heapq.heappop(pq)\n",
    "\n",
    "            if current_node == end:\n",
    "                path = []\n",
    "                while current_node:\n",
    "                    path.append(current_node)\n",
    "                    current_node = previous[current_node]\n",
    "                return path[::-1], current_distance\n",
    "\n",
    "            for neighbor in graph.neighbors(current_node):  # Use NetworkX's neighbors method\n",
    "                distance = current_distance + 1  # All edges have weight of 1\n",
    "                if distance < distances[neighbor]:\n",
    "                    distances[neighbor] = distance\n",
    "                    previous[neighbor] = current_node\n",
    "                    heapq.heappush(pq, (distance, neighbor))\n",
    "\n",
    "        return None, float('infinity')\n",
    "\n",
    "    required_tables = set(required_tables) - {start, end}\n",
    "    best_path = None\n",
    "    best_distance = float('infinity')\n",
    "\n",
    "    # Depth-first search (DFS) to explore all paths through required tables\n",
    "    def dfs(current_path, current_distance, remaining_required):\n",
    "        nonlocal best_path, best_distance\n",
    "\n",
    "        if not remaining_required:\n",
    "            path, distance = dijkstra(G, current_path[-1], end)\n",
    "            if path:\n",
    "                total_path = current_path + path[1:]\n",
    "                total_distance = current_distance + distance\n",
    "                if total_distance < best_distance:\n",
    "                    best_path = total_path\n",
    "                    best_distance = total_distance\n",
    "            return\n",
    "\n",
    "        for node in remaining_required:\n",
    "            path, distance = dijkstra(G, current_path[-1], node)\n",
    "            if path:\n",
    "                new_path = current_path + path[1:]\n",
    "                new_distance = current_distance + distance\n",
    "                new_remaining = remaining_required - {node}\n",
    "                dfs(new_path, new_distance, new_remaining)\n",
    "\n",
    "    # Start DFS from the start node with an empty path and zero distance\n",
    "    dfs([start], 0, required_tables)\n",
    "    print(best_path)\n",
    "    print(best_distance)\n",
    "\n",
    "    return best_path, best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('products', 'categories'), ('orders', 'customers'), ('order_items', 'orders'), ('order_items', 'products')]\n"
     ]
    }
   ],
   "source": [
    "print(dir_g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "inf\n",
      "None\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "required_tables_graph(dir_g, \"categories\", \"orders\", [\"categories\", \"products\", \"orders\"])\n",
    "\n",
    "start_node = 'products'\n",
    "end_node = ''\n",
    "required_tables_list = ['categories', 'products', 'orders']\n",
    "\n",
    "# Find the shortest path through required tables using the modified function\n",
    "path_result, total_distance_result = required_tables_graph(dir_g, start_node, end_node, required_tables_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ordered_set import OrderedSet\n",
    "\n",
    "# refine logic\n",
    "def join_clause(req_schema: dict, db_schema: dict):\n",
    "    clause = \"\"\n",
    "    max_cols = 0\n",
    "    prim_table = None\n",
    "    # change logic based on foreign key numbers\n",
    "    for table, cols in req_schema.items():\n",
    "        if len(cols) > max_cols:\n",
    "            max_cols = len(cols)\n",
    "            prim_table = table\n",
    "    \n",
    "    # pk_col = db_schema[prim_table]['pk']\n",
    "    print(prim_table)\n",
    "\n",
    "    # create graph from Database schema\n",
    "    db_graph = create_dir_graph(db_schema)\n",
    "\n",
    "    print(db_graph)\n",
    "\n",
    "    required_tables = list(req_schema.keys())\n",
    "\n",
    "    print(required_tables)\n",
    "\n",
    "    min_dist = float('inf')\n",
    "    for st_table in required_tables:\n",
    "        for end_table in required_tables:\n",
    "            sub_graph, distance = required_tables_graph(db_graph, st_table, end_table, required_tables)\n",
    "            if distance < min_dist:\n",
    "                join_graph = OrderedSet(sub_graph)\n",
    "                min_dist = distance\n",
    "\n",
    "    print(join_graph)\n",
    "\n",
    "    req_graph = []\n",
    "\n",
    "    for edge in db_graph.edges:\n",
    "        # assumption binary relations between tables\n",
    "        if edge[0] in join_graph and edge[1] in join_graph:\n",
    "            req_graph.append(edge)\n",
    "\n",
    "    print(\"required graph: \", req_graph)\n",
    "\n",
    "    for i, edge in enumerate(req_graph):\n",
    "        table1 = edge[0]\n",
    "        table2 = edge[1]\n",
    "        print(edge)\n",
    "        if table1 in db_schema[table2]['fk']:\n",
    "            # print(\"1\")\n",
    "            fk_col = db_schema[table2]['fk'][table1] # foreign key corresponding to 2nd table  primary key\n",
    "            pk_col = db_schema[table1]['pk'][0] # primary key of 2nd table\n",
    "            clause += f\"JOIN {table1} ON {table2}.{fk_col}={table1}.{pk_col} \\n\"\n",
    "        else:\n",
    "            fk_col = db_schema[table1]['fk'][table] # foreign key corresponding to 2nd table  primary key\n",
    "            pk_col = db_schema[table2]['pk'][0] # primary key of 2nd table\n",
    "            clause += f\"JOIN {table2} ON {table1}.{fk_col}={table2}.{pk_col} \\n\"\n",
    "        \n",
    "        # print(\"test: \", clause)\n",
    "\n",
    "    # for i, table in enumerate(join_graph):\n",
    "    #     if not db_schema[table]['fk']:\n",
    "    #         continue\n",
    "        \n",
    "    # print(clause)\n",
    "\n",
    "    # for table in req_schema.keys():\n",
    "    #     if table != prim_table:\n",
    "    #         fk_col = db_schema[prim_table]['fk'][table] # foreign key corresponding to 2nd table  primary key\n",
    "    #         pk_col = db_schema[table]['pk'][0] # primary key of 2nd table\n",
    "    #         clause += f\"JOIN {table} ON {prim_table}.{fk_col}={table}.{pk_col} \\n\"\n",
    "    #         print(clause)\n",
    "    return clause\n",
    "\n",
    "# create a graph out of db schema and select required tables starting with primary table (using shortest route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers\n",
      "['products', 'categories', 'customers', 'orders', 'order_items']\n",
      "[('products', 'categories'), ('orders', 'customers'), ('order_items', 'orders'), ('order_items', 'products')]\n",
      "DiGraph with 5 nodes and 4 edges\n",
      "['products', 'customers', 'orders']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'join_graph' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mjoin_clause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSQL\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[93], line 34\u001b[0m, in \u001b[0;36mjoin_clause\u001b[0;34m(req_schema, db_schema)\u001b[0m\n\u001b[1;32m     31\u001b[0m             join_graph \u001b[38;5;241m=\u001b[39m OrderedSet(sub_graph)\n\u001b[1;32m     32\u001b[0m             min_dist \u001b[38;5;241m=\u001b[39m distance\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mjoin_graph\u001b[49m)\n\u001b[1;32m     36\u001b[0m req_graph \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m db_graph\u001b[38;5;241m.\u001b[39medges:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# assumption binary relations between tables\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'join_graph' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "print(join_clause(req, SQL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers\n",
      "Nodes: ['products', 'categories', 'customers', 'orders', 'order_items']\n",
      "Edges: [('products', 'categories'), ('products', 'order_items'), ('customers', 'orders'), ('orders', 'order_items')]\n",
      "Graph with 5 nodes and 4 edges\n",
      "['products', 'customers', 'orders']\n",
      "OrderedSet(['products', 'order_items', 'orders', 'customers'])\n",
      "required graph:  [('products', 'order_items'), ('customers', 'orders'), ('orders', 'order_items')]\n",
      "('products', 'order_items')\n",
      "('customers', 'orders')\n",
      "('orders', 'order_items')\n",
      "JOIN products ON order_items.product_id=products.product_id \n",
      "JOIN customers ON orders.customer_id=customers.customer_id \n",
      "JOIN orders ON order_items.order_id=orders.order_id \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(join_clause(req, SQL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(graph, start, end, visited):\n",
    "    if start == end:\n",
    "        return [start]\n",
    "    for neighbor in graph[start]:\n",
    "        if neighbor not in visited:\n",
    "            path = find_path(graph, neighbor, end, visited | {neighbor})\n",
    "            if path:\n",
    "                return [start] + path\n",
    "    return None\n",
    "\n",
    "def get_join_condition(sql, from_table, to_table):\n",
    "    for column, fk_info in sql[from_table].get('fk', {}).items():\n",
    "        if fk_info.split('.')[0] == to_table:\n",
    "            return f'{from_table}.{column} = {fk_info}'\n",
    "    for column, fk_info in sql[to_table].get('fk', {}).items():\n",
    "        if fk_info.split('.')[0] == from_table:\n",
    "            return f'{to_table}.{column} = {fk_info}'\n",
    "    return None\n",
    "\n",
    "def generate_sql_join(sql, req):\n",
    "    join_statements = []\n",
    "    tables = list(req.keys())\n",
    "    \n",
    "    # Start with the base table (assuming it's the first table in req)\n",
    "    base_table = tables[0]\n",
    "    join_statements.append(f'FROM {base_table}')\n",
    "    \n",
    "    # Create a graph of table relationships\n",
    "    graph = {table: set() for table in sql.keys()}\n",
    "    for table, info in sql.items():\n",
    "        for fk_table, fk_column in info.get('fk', {}).items():\n",
    "            graph[table].add(fk_table)\n",
    "            graph[fk_table].add(table)\n",
    "    \n",
    "    # Find the join path\n",
    "    visited = set([base_table])\n",
    "    for table in tables[1:]:\n",
    "        path = find_path(graph, base_table, table, visited)\n",
    "        if path:\n",
    "            for i in range(len(path) - 1):\n",
    "                from_table, to_table = path[i], path[i+1]\n",
    "                join_condition = get_join_condition(sql, from_table, to_table)\n",
    "                join_statements.append(f'JOIN {to_table} ON {join_condition}')\n",
    "                visited.add(to_table)\n",
    "    \n",
    "    return '\\n'.join(join_statements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FROM products\\nJOIN order_items ON None\\nJOIN orders ON None\\nJOIN customers ON None'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sql_join(SQL, req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FROM order_items'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"FROM order_items\n",
    "JOIN products on order_items.product_id=products.product_id\n",
    "JOIN orders on orders.order_id = order_items.order_id\n",
    "JOIN customers on order.customer_id = customer.customer_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SQL = {\n",
    "    \"books\": {\n",
    "        \"pk\": [\"book_id\"],\n",
    "        \"fk\": {\"authors\": \"author_id\"},\n",
    "        \"book_id\": \"INT\",\n",
    "        \"title\": \"VARCHAR(255)\",\n",
    "        \"author_id\": \"INT\",\n",
    "        \"isbn\": \"VARCHAR(13)\",\n",
    "        \"publication_year\": \"INT\",\n",
    "        \"price\": \"DECIMAL(10, 2)\",\n",
    "        \"stock_quantity\": \"INT\"\n",
    "    },\n",
    "    \"authors\": {\n",
    "        \"pk\": [\"author_id\"],\n",
    "        \"fk\": {},\n",
    "        \"author_id\": \"INT\",\n",
    "        \"first_name\": \"VARCHAR(50)\",\n",
    "        \"last_name\": \"VARCHAR(50)\",\n",
    "        \"birth_date\": \"DATE\",\n",
    "        \"nationality\": \"VARCHAR(50)\",\n",
    "        \"biography\": \"TEXT\"\n",
    "    }\n",
    "}\n",
    "\n",
    "req = {\n",
    "    \"books\": [\n",
    "        \"book_id\",\n",
    "        \"title\",\n",
    "        \"stock_quantity\"\n",
    "    ],\n",
    "    \"authors\": [\n",
    "        \"author_id\",\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "    ]\n",
    "}\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SQL = {\n",
    "    \"employees\": {\n",
    "        \"pk\": [\"employee_id\"],\n",
    "        \"fk\": {\"departments\": \"department_id\"},\n",
    "        \"employee_id\": \"INT\",\n",
    "        \"first_name\": \"VARCHAR(50)\",\n",
    "        \"last_name\": \"VARCHAR(50)\",\n",
    "        \"email\": \"VARCHAR(100)\",\n",
    "        \"phone_number\": \"VARCHAR(20)\",\n",
    "        \"hire_date\": \"DATE\",\n",
    "        \"job_title\": \"VARCHAR(100)\",\n",
    "        \"salary\": \"DECIMAL(10, 2)\",\n",
    "        \"department_id\": \"INT\"\n",
    "    },\n",
    "    \"departments\": {\n",
    "        \"pk\": [\"department_id\"],\n",
    "        \"fk\": {\"employees\": \"manager_id\"},\n",
    "        \"department_id\": \"INT\",\n",
    "        \"department_name\": \"VARCHAR(100)\",\n",
    "        \"manager_id\": \"INT\",\n",
    "        \"location\": \"VARCHAR(100)\"\n",
    "    },\n",
    "    \"job_history\": {\n",
    "        \"pk\": [\"employee_id\", \"start_date\"],\n",
    "        \"fk\": {\n",
    "            \"employees\": \"employee_id\",\n",
    "            \"departments\": \"department_id\"\n",
    "        },\n",
    "        \"employee_id\": \"INT\",\n",
    "        \"start_date\": \"DATE\",\n",
    "        \"end_date\": \"DATE\",\n",
    "        \"job_title\": \"VARCHAR(100)\",\n",
    "        \"department_id\": \"INT\"\n",
    "    }\n",
    "}\n",
    "\n",
    "req = {\n",
    "    \"employees\": [\n",
    "        \"employee_id\",\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "        \"job_title\"\n",
    "    ],\n",
    "    \"departments\": [\n",
    "        \"department_id\",\n",
    "        \"department_name\",\n",
    "        \"location\"\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "SQL = {\n",
    "    \"products\": {\n",
    "        \"pk\": [\"product_id\"],\n",
    "        \"fk\": {\"categories\": \"category_id\"},\n",
    "        \"product_id\": \"INT\",\n",
    "        \"product_name\": \"VARCHAR(255)\",\n",
    "        \"description\": \"TEXT\",\n",
    "        \"price\": \"DECIMAL(10, 2)\",\n",
    "        \"stock_quantity\": \"INT\",\n",
    "        \"category_id\": \"INT\"\n",
    "    },\n",
    "    \"categories\": {\n",
    "        \"pk\": [\"category_id\"],\n",
    "        \"fk\": {},\n",
    "        \"category_id\": \"INT\",\n",
    "        \"category_name\": \"VARCHAR(100)\",\n",
    "        \"description\": \"TEXT\"\n",
    "    },\n",
    "    \"customers\": {\n",
    "        \"pk\": [\"customer_id\"],\n",
    "        \"fk\": {},\n",
    "        \"customer_id\": \"INT\",\n",
    "        \"first_name\": \"VARCHAR(50)\",\n",
    "        \"last_name\": \"VARCHAR(50)\",\n",
    "        \"email\": \"VARCHAR(100)\",\n",
    "        \"phone_number\": \"VARCHAR(20)\",\n",
    "        \"address\": \"TEXT\"\n",
    "    },\n",
    "    \"orders\": {\n",
    "        \"pk\": [\"order_id\"],\n",
    "        \"fk\": {\n",
    "            \"customers\": \"customer_id\"\n",
    "        },\n",
    "        \"order_id\": \"INT\",\n",
    "        \"customer_id\": \"INT\",\n",
    "        \"order_date\": \"DATE\",\n",
    "        \"total_amount\": \"DECIMAL(10, 2)\",\n",
    "        \"status\": \"VARCHAR(20)\"\n",
    "    },\n",
    "    \"order_items\": {\n",
    "        \"pk\": [\"order_item_id\"],\n",
    "        \"fk\": {\n",
    "            \"orders\": \"order_id\",\n",
    "            \"products\": \"product_id\"\n",
    "        },\n",
    "        \"order_item_id\":\"INT\",\n",
    "        \"order_id\": \"INT\",\n",
    "        \"product_id\": \"INT\",\n",
    "        \"quantity\": \"INT\",\n",
    "        \"unit_price\": \"DECIMAL(10, 2)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "req = {\n",
    "    \"products\": [\n",
    "        \"product_id\",\n",
    "        \"product_name\",\n",
    "        \"price\"\n",
    "    ],\n",
    "    \"customers\": [\n",
    "        \"customer_id\",\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "        \"email\"\n",
    "    ],\n",
    "    \"orders\": [\n",
    "        \"order_id\",\n",
    "        \"customer_id\",\n",
    "        \"order_date\",\n",
    "        \"total_amount\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers\n",
      "Nodes: ['products', 'categories', 'customers', 'orders', 'order_items']\n",
      "Edges: [('products', 'categories'), ('products', 'order_items'), ('customers', 'orders'), ('orders', 'order_items')]\n",
      "['products', 'customers', 'orders']\n",
      "OrderedSet(['products', 'order_items', 'orders', 'customers'])\n",
      "required graph:  [('products', 'order_items'), ('customers', 'orders'), ('orders', 'order_items')]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'orders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjoin_clause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSQL\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 44\u001b[0m, in \u001b[0;36mjoin_clause\u001b[0;34m(req_schema, db_schema)\u001b[0m\n\u001b[1;32m     42\u001b[0m table2 \u001b[38;5;241m=\u001b[39m edge[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table1 \u001b[38;5;129;01min\u001b[39;00m db_schema[table2][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfk\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 44\u001b[0m     fk_col \u001b[38;5;241m=\u001b[39m \u001b[43mdb_schema\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtable2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# foreign key corresponding to 2nd table  primary key\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     pk_col \u001b[38;5;241m=\u001b[39m db_schema[table1][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpk\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# primary key of 2nd table\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     clause \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJOIN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ON \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfk_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpk_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'orders'"
     ]
    }
   ],
   "source": [
    "join_clause(req, SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condiiton identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# difference between where and having\n",
    "def identify_condition(tokens):\n",
    "    conditions = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.lower() == \"where\":\n",
    "            conditions.append(\" \".join(tokens[i+1:])) # refine with \n",
    "            break\n",
    "\n",
    "    print(f\"Conditions: {conditions}\")\n",
    "    # Example Output: Conditions: [\"age > 30\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
